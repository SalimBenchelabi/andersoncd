{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plot influence of linear system regularization\n\nWhy regularizing the linear system seems to hurt Anderson performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n\nimport numpy as np\nimport seaborn as sns\nfrom scipy import sparse\nfrom numpy.linalg import norm\nimport matplotlib.pyplot as plt\nfrom scipy.sparse.linalg import cg\nfrom celer.datasets import fetch_libsvm\nfrom celer.plot_utils import configure_plt\n\nfrom extracd.lasso import solver_enet, primal_enet, apcg\n\n\nconfigure_plt()\n\nn_features = 1000\ncorr = 0.5\nX, y = fetch_libsvm('rcv1_train')\nX = X[:, :n_features]\n\nif not sparse.issparse(X):\n    y -= y.mean()\n    X -= np.mean(X, axis=0)[None, :]\n    X /= norm(X, axis=0)[None, :]\nelse:\n    X.multiply(1 / sparse.linalg.norm(X, axis=0))\n    y -= y.mean()\n    y /= norm(y)\n\nalpha_max = np.max(np.abs(X.T @ y))\n\nalpha = 0\ntol = 1e-15\nE_cg = []\nE_cg.append(norm(y) ** 2 / 2)\n\nmax_iter = 1500\n\n\ndef my_func(x):\n    pobj = primal_enet(y - X @ x, x, alpha)\n    E_cg.append(pobj)\n\n\nw_star = cg(X.T @ X, X.T @ y, callback=my_func, maxiter=max_iter, tol=1e-32)[0]\n\nE_cg = np.array(E_cg)\n\n\nf_gap = 10\nreturn_all = False\n\n\nall_algos = [\n    ('cd', False, None, None),\n    ('cd', True, 6, 1e-3),\n    ('cd', True, 6, 1e-4),\n    ('cd', True, 6, 1e-5),\n    ('cd', True, 6, 1e-10),\n    ('cd', True, 6, None),\n]\n\ndict_coef = defaultdict(lambda: 1)\ndict_coef['cdsym'] = 2\ndict_coef['cd2'] = 2\n\n\ndict_Es = {}\n\nfor algo in all_algos:\n    if algo[0] == 'apcg':\n        w, E, gaps = apcg(\n            X, y, alpha, max_iter=max_iter, tol=tol, f_gap=f_gap)\n    else:\n        w, E, _ = solver_enet(\n            X, y, alpha=alpha, f_gap=f_gap, max_iter=max_iter, tol=tol,\n            return_all=return_all, algo=algo[0], use_acc=algo[1],\n            K=algo[2], reg_amount=algo[3])\n    dict_Es[algo] = E.copy()\n\n\ncurrent_palette = sns.color_palette(\"colorblind\")\ndict_color = {}\ndict_color[\"pgd\"] = current_palette[0]\ndict_color[\"fista\"] = current_palette[0]\ndict_color[\"cd\"] = current_palette[1]\ndict_color[\"apcg\"] = current_palette[1]\ndict_color['cdsym'] = current_palette[2]\ndict_color[\"cd2\"] = current_palette[3]\n\ndict_algo_name = {}\ndict_algo_name[False, \"pgd\"] = \"GD\"\ndict_algo_name[False, \"cd\"] = \"CD\"\ndict_algo_name[False, \"cdsym\"] = \"CD SYM\"\ndict_algo_name[True, \"pgd\"] = \"GD - Anderson\"\ndict_algo_name[True, \"cd\"] = \"CD - Anderson\"\ndict_algo_name[True, \"cdsym\"] = \"CD SYM - Anderson\"\ndict_algo_name[False, \"fista\"] = \"GD - inertial\"\ndict_algo_name[False, \"apcg\"] = \"CD - inertial\"\n\n\np_star = primal_enet(y - X @ w_star, w_star, alpha)\nfor E in dict_Es.values():\n    p_star = min(p_star, min(E))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "starts plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "current_palette = sns.color_palette(\"colorblind\")\n\nplt.close('all')\nfig, ax = plt.subplots(figsize=(8, 5))\n\nfor i, algo in enumerate(all_algos):\n    E = dict_Es[algo]\n    use_acc = algo[1]\n    K = algo[2]\n    if use_acc:\n        linestyle = 'dashed'\n    elif algo[0].startswith(('fista', 'apcg')):\n        linestyle = 'dotted'\n    else:\n        linestyle = 'solid'\n\n    if not use_acc:\n        label = \"CD, no acc\"\n        color = current_palette[1]\n    else:\n        if algo[3] is None:\n            label = r\"$\\lambda_{\\mathrm{reg}} = 0$\"\n            color = current_palette[1]\n        else:\n            label = r\"$\\lambda_{\\mathrm{reg}} = 10^{%d}$\" % np.log10(algo[3])\n            color = plt.cm.viridis((i + 1) / len(all_algos))\n    ax.semilogy(\n        dict_coef[algo[0]] * f_gap * np.arange(len(E)), E - p_star,\n        label=label, color=color, linestyle=linestyle)\n\n\nax.set_yticks((1e-15, 1e-10, 1e-5, 1))\nplt.ylabel(r\"$f(x^{(k)}) - f(x^{*})$\")\nplt.xlabel(r\"iteration $k$\")\nplt.tight_layout()\nplt.legend()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}