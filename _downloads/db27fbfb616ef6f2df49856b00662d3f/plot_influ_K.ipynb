{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plot influence of parameter K\n\nHow many points must be extrapolated for optimal performance?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom scipy import sparse\nfrom numpy.linalg import norm\nfrom celer.datasets import fetch_libsvm\nfrom celer.plot_utils import configure_plt\n\nfrom extracd.lasso import solver_enet\n\n\nconfigure_plt()\n\ndataset = \"rcv1_train\"\nX, y = fetch_libsvm(dataset)\nX = X[:, :1000]\n\nif not sparse.issparse(X):\n    y -= y.mean()\n    X -= np.mean(X, axis=0)[None, :]\n    X /= norm(X, axis=0)[None, :]\nelse:\n    X.multiply(1 / sparse.linalg.norm(X, axis=0))\n    y -= y.mean()\n    y /= norm(y)\n\nalpha_max = np.max(np.abs(X.T @ y))\n\nalpha = 0\ntol = 1e-15\nmax_iter = 1500\nf_gap = 10\n\ndict_algo = {}\n\ndict_algo = [\n    ('cd', False, 0),\n    ('cd', True, 2),\n    ('cd', True, 3),\n    ('cd', True, 4),\n    ('cd', True, 5),\n    ('cd', True, 10),\n    ('cd', True, 20),\n]\n\ndict_coef = {}\ndict_coef['gd'] = 1\ndict_coef['cd'] = 1\ndict_coef['cdsym'] = 2\ndict_coef['cd2'] = 2\n\n\ndict_Es = {}\n\nfor algo in dict_algo:\n    w, E, _ = solver_enet(\n        X, y, alpha=alpha, f_gap=f_gap, max_iter=max_iter, tol=tol,\n        return_all=False, algo=algo[0], use_acc=algo[1],\n        K=algo[2])\n    dict_Es[algo] = E.copy()\n\n\ncurrent_palette = sns.color_palette(\"colorblind\")\ndict_color = {}\ndict_color[\"gd\"] = current_palette[0]\ndict_color[\"cd\"] = current_palette[1]\ndict_color['cdsym'] = current_palette[2]\ndict_color[\"cd2\"] = current_palette[3]\n\n\np_star = np.inf\nfor E in dict_Es.values():\n    p_star = min(p_star, min(E))\n\n\nfig, ax = plt.subplots(figsize=[9.3, 5.6])\nfor i, algo in enumerate(dict_algo):\n    E = dict_Es[algo]\n    K = algo[2]\n    if K == 0:\n        label = \"CD, no acc\"\n        linestyle = 'solid'\n        color = dict_color[\"cd\"]\n    else:\n        label = \"CD, K=%i\" % (algo[2])\n        linestyle = 'dashed'\n        color = plt.cm.viridis(i / len(dict_algo))\n    ax.semilogy(\n        dict_coef[algo[0]] * f_gap * np.arange(len(E)), E - p_star,\n        label=label, color=color, linestyle=linestyle)\n\n\nax.set_xlabel(r\"iteration $k$\")\nax.set_xlim(0, 1500)\nax.set_yticks((1e-15, 1e-10, 1e-5, 1))\nax.set_ylabel(r\"$f(x^{(k)}) - f(x^*)$\")\nplt.tight_layout()\n\nplt.legend()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}