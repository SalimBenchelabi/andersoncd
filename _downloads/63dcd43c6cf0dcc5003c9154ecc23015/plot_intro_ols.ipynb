{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparison of CD, GD, inertial and Anderson acceleration\n\nCD outperforms GD, and Anderson acceleration outperforms inertial acceleration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import sparse\nfrom numpy.linalg import norm\nfrom scipy.sparse.linalg import cg\nfrom celer.datasets import fetch_libsvm\nfrom celer.plot_utils import configure_plt\n\nfrom extracd.lasso import solver_enet, primal_enet, apcg\n\n\nplot_all_algos = True\n\nconfigure_plt()\n\nn_features = 1000\nX, y = fetch_libsvm('rcv1_train')\nX = X[:, :n_features]\n\nif not sparse.issparse(X):\n    y -= y.mean()\n    X -= np.mean(X, axis=0)[None, :]\n    X /= norm(X, axis=0)[None, :]\nelse:\n    X.multiply(1 / sparse.linalg.norm(X, axis=0))\n    y -= y.mean()\n    y /= norm(y)\n\nalpha_max = np.max(np.abs(X.T @ y))\n\nalpha = 0\ntol = 1e-15\nE_cg = []\nE_cg.append(norm(y) ** 2 / 2)\nmax_iter = 2000\n\n\ndef callback(x):\n    pobj = primal_enet(y - X @ x, x, alpha)\n    E_cg.append(pobj)\n\n\nw_star = cg(\n    X.T @ X, X.T @ y, callback=callback, maxiter=max_iter, tol=1e-32)[0]\nE_cg = np.array(E_cg)\n\n\nf_gap = 10\nreturn_all = False\nall_algos = [\n    ('pgd', False, 1),\n    ('pgd', True, 5),\n    ('fista', False, 1),\n    ('cd', False, 1),\n    ('cd', True, 5),\n    ('apcg', False, 1),\n]\n\n\ndict_coef = defaultdict(lambda: 1)\ndict_coef['cdsym'] = 2\ndict_coef['cd2'] = 2\n\n\ndict_Es = {}\n\nfor algo in all_algos:\n    if algo[0] == 'apcg':\n        w, E, gaps = apcg(\n            X, y, alpha, max_iter=max_iter, tol=tol, f_gap=f_gap)\n    else:\n        w, E, _ = solver_enet(\n            X, y, alpha=alpha, f_gap=f_gap, max_iter=max_iter, tol=tol,\n            return_all=return_all, algo=algo[0], use_acc=algo[1],\n            K=algo[2])\n    dict_Es[algo] = E.copy()\n\n\ncurrent_palette = sns.color_palette(\"colorblind\")\ndict_color = {}\ndict_color[\"pgd\"] = current_palette[0]\ndict_color[\"fista\"] = current_palette[0]\ndict_color[\"cd\"] = current_palette[1]\ndict_color[\"apcg\"] = current_palette[1]\ndict_color['cdsym'] = current_palette[2]\ndict_color[\"cd2\"] = current_palette[3]\n\ndict_algo_name = {}\ndict_algo_name[False, \"pgd\"] = \"GD\"\ndict_algo_name[False, \"cd\"] = \"CD\"\ndict_algo_name[False, \"cdsym\"] = \"CD SYM\"\ndict_algo_name[True, \"pgd\"] = \"GD - Anderson\"\ndict_algo_name[True, \"cd\"] = \"CD - Anderson\"\ndict_algo_name[True, \"cdsym\"] = \"CD SYM - Anderson\"\ndict_algo_name[False, \"fista\"] = \"GD - inertial\"\ndict_algo_name[False, \"apcg\"] = \"CD - inertial\"\n\n\np_star = primal_enet(y - X @ w_star, w_star, alpha)\nfor E in dict_Es.values():\n    p_star = min(p_star, min(E))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "starts plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.close('all')\nfig, ax = plt.subplots(figsize=(9, 6))\n\n\nfor i, algo in enumerate(all_algos):\n    E = dict_Es[algo]\n    use_acc = algo[1]\n    K = algo[2]\n    if use_acc:\n        linestyle = 'dashed'\n    elif algo[0].startswith(('fista', 'apcg')):\n        linestyle = 'dotted'\n    else:\n        linestyle = 'solid'\n\n    ax.semilogy(\n        dict_coef[algo[0]] * f_gap * np.arange(len(E)), E - p_star,\n        label=dict_algo_name[use_acc, algo[0]],\n        color=dict_color[algo[0]], linestyle=linestyle)\n\nax.semilogy(\n    np.arange(len(E_cg)), E_cg - p_star, label=\"conjugate grad.\",\n    color='black', linestyle='dashdot')\n\nplt.ylabel(r\"$f(x^{(k)}) - f(x^{*})$\")\nplt.xlabel(r\"iteration $k$\")\nax.set_yticks((1e-15, 1e-10, 1e-5, 1e0))\nplt.tight_layout()\n\n\nplt.legend()\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}