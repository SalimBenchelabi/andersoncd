{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plot convergence of CD, pseudo-symmetric CD, and Anderson versions\n\nTODO desc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n\nimport numpy as np\nimport seaborn as sns\nfrom scipy import sparse\nfrom numpy.linalg import norm\nimport matplotlib.pyplot as plt\nfrom scipy.sparse.linalg import cg\nfrom scipy.optimize import fmin_l_bfgs_b\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import label_binarize\nfrom celer.datasets import fetch_libsvm\nfrom celer.plot_utils import configure_plt\n\nfrom extracd.utils import power_method\nfrom extracd.lasso import solver_enet, primal_enet\nfrom extracd.logreg import solver_logreg, primal_logreg\n\n\nconfigure_plt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pb = \"logreg\"\n# pb = \"lasso\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = \"rcv1_train\"\n# dataset = \"real-sim\"\n# dataset = \"leukemia\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if dataset == \"real-sim\":\n    n_features = 2000\nelif dataset == \"rcv1_train\":\n    # n_features = 1000\n    n_features = 5000\nelif dataset == 'leukemia':\n    n_features = 1000\n\n# load and center data\nif dataset == \"leukemia\":\n    data = fetch_openml(\"leukemia\")\n    X = np.asfortranarray(data.data)\n    y = 2 * label_binarize(data.target, classes=np.unique(data.target)) - 1\n    y = y.squeeze().astype(float)\nelse:\n    X, y = fetch_libsvm(dataset)\n\nX = X[:, :n_features]\nif not sparse.issparse(X):\n    X -= np.mean(X, axis=0)[None, :]\n    X /= norm(X, axis=0)[None, :]\nelse:\n    X.multiply(1 / sparse.linalg.norm(X, axis=0))\n\nif pb == 'lasso':\n    y -= y.mean()\n    y /= norm(y)\n\nif dataset == 'real-sim':\n    max_iter = 1_000\nelse:\n    max_iter = 1_000\n\nf_gap = 10\ndiv_alpha = np.inf  # ols\ntol = 1e-15\n\n\nE_optimal = []\nif pb == \"logreg\":\n    rho = power_method(X) ** 2 / 100_000  # a bit of enet\n    alpha_max = np.max(np.abs(X.T @ y)) / 2\n    E_optimal.append(np.log(2) * len(y))\n    label_opt = \"L-BFGS\"\n\n    def callback(x):\n        pobj = primal_logreg(X @ x, y, x, 0, rho)\n        E_optimal.append(pobj)\n\n    def obj(x):\n        return np.log(1 + np.exp(- y * (X @ x))).sum() + rho * x @ x / 2\n\n    def fprime(x):\n        return - X.T @ (y / (1 + np.exp(y * (X @ x)))) + rho * x\n\n    res = fmin_l_bfgs_b(obj, np.zeros(\n        X.shape[1]), fprime=fprime, callback=callback, factr=0.01, pgtol=0,\n        maxiter=max_iter)\nelse:\n    alpha_max = np.max(np.abs(X.T @ y))\n    alpha = alpha_max / div_alpha\n    rho = 0  # no elastic net\n    E_optimal.append(norm(y) ** 2 / 2)\n    label_opt = \"conjugate grad.\"\n\n    def callback(x):\n        pobj = primal_enet(y - X @ x, x, alpha)\n        E_optimal.append(pobj)\n    w_star = cg(\n        X.T @ X, X.T @ y, callback=callback, maxiter=max_iter, tol=1e-32)[0]\nE_optimal = np.array(E_optimal)\n\nalpha = alpha_max / div_alpha\n\n\nall_algos = [\n    ('cd', False, None),\n    ('cd', True, 5),\n    ('cdsym', False, None),\n    ('cdsym', True, 5),\n]\n\n\ndict_coef = defaultdict(lambda: 1)\ndict_coef['cdsym'] = 2\n\ndict_Es = {}\n\n\nfor algo in all_algos:\n    if pb == \"lasso\":\n        w, E, _ = solver_enet(\n            X, y, alpha=alpha, f_gap=f_gap,\n            max_iter=int(max_iter/dict_coef[algo[0]]), tol=tol, algo=algo[0],\n            use_acc=algo[1], K=algo[2])\n    elif pb == \"logreg\":\n        w, E, _ = solver_logreg(\n            X, y, alpha=alpha, rho=rho, f_gap=f_gap,\n            max_iter=max_iter//dict_coef[algo[0]], tol=tol,\n            algo=algo[0], use_acc=algo[1], K=algo[2])\n    dict_Es[algo] = E\n\n\ncurrent_palette = sns.color_palette(\"colorblind\")\ndict_color = {}\ndict_color[\"cd\"] = current_palette[1]\ndict_color['cdsym'] = current_palette[2]\n\ndict_algo_name = {}\ndict_algo_name[False, \"cd\"] = \"CD\"\ndict_algo_name[False, \"cdsym\"] = \"CD sym\"\ndict_algo_name[True, \"cd\"] = \"CD - Anderson\"\ndict_algo_name[True, \"cdsym\"] = \"CD sym - Anderson\"\n\n\np_star = E_optimal[-1]\nfor E in dict_Es.values():\n    p_star = min(p_star, min(E))\n\nplt.close('all')\nfig, ax = plt.subplots(figsize=(10, 5))\nfor i, algo in enumerate(all_algos):\n    E = dict_Es[algo]\n    use_acc = algo[1]\n    K = algo[2]\n    if use_acc:\n        linestyle = 'dashed'\n    elif algo[0] == 'fista':\n        linestyle = 'dotted'\n    else:\n        linestyle = 'solid'\n\n    ax.semilogy(\n        dict_coef[algo[0]] * f_gap * np.arange(len(E)), E - p_star,\n        label=dict_algo_name[use_acc, algo[0]],\n        color=dict_color[algo[0]], linestyle=linestyle)\n\nax.semilogy(\n    np.arange(len(E_optimal)), E_optimal - p_star,\n    label=label_opt, color='black', linestyle='dashdot')\n\ndict_dataset = {}\ndict_dataset[\"rcv1_train\"] = \"rcv1\"\ndict_dataset[\"real-sim\"] = \"real_sim\"  # use _ not - for latex\ndict_dataset[\"leukemia\"] = \"leukemia\"\n\nif div_alpha == np.inf:\n    str_info = \"%s %i st columns\" % (dict_dataset[dataset], n_features)\n    title = \"OLS \" + str_info if pb == \"lasso\" else \"logreg \" + str_info\nelse:\n    title = r'%s, $\\lambda = \\lambda_{\\mathrm{max}} / %s $' % (\n        pb, div_alpha)\n\nplt.ylabel(r\"$f(x^{(k)}) - f(x^{*})$\")\nplt.xlabel(\"nb gradient calls\")\nplt.ylim((1e-10, None))\nplt.tight_layout()\n\nplt.legend()\nplt.title(title.replace('_', ' '))\nplt.show(block=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}