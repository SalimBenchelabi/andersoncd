
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_cd_sym.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_cd_sym.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_cd_sym.py:


Convergence of CD, pseudo-symmetric CD, and their Anderson versions
==================================================================

On least squares and logistic regression, performance of pseudo-symmetric
coordinate descent.

.. GENERATED FROM PYTHON SOURCE LINES 9-28

.. code-block:: default

    from collections import defaultdict

    import numpy as np
    import seaborn as sns
    from scipy import sparse
    from numpy.linalg import norm
    import matplotlib.pyplot as plt
    from scipy.sparse.linalg import cg
    from scipy.optimize import fmin_l_bfgs_b
    from libsvmdata import fetch_libsvm

    from andersoncd.plot_utils import configure_plt
    from andersoncd.utils import power_method
    from andersoncd.lasso import solver_enet, primal_enet
    from andersoncd.logreg import solver_logreg, primal_logreg


    configure_plt()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    usetex mode requires TeX.




.. GENERATED FROM PYTHON SOURCE LINES 29-30

Load the data:

.. GENERATED FROM PYTHON SOURCE LINES 30-38

.. code-block:: default

    dataset = "real-sim"
    n_features = 1000
    X, y = fetch_libsvm(dataset)

    X = X[:, :n_features]
    X.multiply(1 / sparse.linalg.norm(X, axis=0))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Dataset: real-sim

    <72309x1000 sparse matrix of type '<class 'numpy.float64'>'
    	with 1124310 stored elements in COOrdinate format>



.. GENERATED FROM PYTHON SOURCE LINES 39-40

Generate figures for both Least Squares and Logistic regression

.. GENERATED FROM PYTHON SOURCE LINES 40-153

.. code-block:: default

    for pb in ("ols", "logreg"):
        if pb == 'lasso':
            y -= y.mean()
            y /= norm(y)

        f_gap = 10
        tol = 1e-15
        max_iter = 750

        # run "best algorithm": conj. grad. for LS, LBFGS for logreg:
        E_optimal = []
        if pb == "logreg":
            rho = power_method(X) ** 2 / 100_000  # a bit of enet regularization
            E_optimal.append(np.log(2) * len(y))
            label_opt = "L-BFGS"

            def callback(x):
                pobj = primal_logreg(X @ x, y, x, 0, rho)
                E_optimal.append(pobj)

            def obj(x):
                return np.log(1 + np.exp(- y * (X @ x))).sum() + rho * x @ x / 2

            def fprime(x):
                return - X.T @ (y / (1 + np.exp(y * (X @ x)))) + rho * x

            fmin_l_bfgs_b(obj, np.zeros(
                X.shape[1]), fprime=fprime, callback=callback, factr=0.01, pgtol=0,
                maxiter=max_iter)
        else:
            alpha = 0
            rho = 0  # no elastic net
            E_optimal.append(norm(y) ** 2 / 2)
            label_opt = "conjugate grad."

            def callback(x):
                pobj = primal_enet(y - X @ x, x, alpha)
                E_optimal.append(pobj)
            cg(X.T @ X, X.T @ y, callback=callback, maxiter=max_iter, tol=1e-32)
        E_optimal = np.array(E_optimal)

        all_algos = [
            ('cd', False),
            ('cd', True),
            ('cdsym', False),
            ('cdsym', True),
        ]

        dict_coef = defaultdict(lambda: 1)
        dict_coef['cdsym'] = 2
        algo_names = {}
        algo_names["cd", False] = "CD"
        algo_names["cdsym", False] = "CD sym"
        algo_names["cd", True] = "CD - Anderson"
        algo_names["cdsym", True] = "CD sym - Anderson"

        dict_Es = {}

        for algo in all_algos:
            print("Running %s" % algo_names[algo])
            if pb == "ols":
                w, E, _ = solver_enet(
                    X, y, alpha=alpha, f_gap=f_gap,
                    max_iter=int(max_iter/dict_coef[algo[0]]), tol=tol,
                    algo=algo[0], use_acc=algo[1])
            elif pb == "logreg":
                w, E, _ = solver_logreg(
                    X, y, alpha=alpha, rho=rho, f_gap=f_gap,
                    max_iter=max_iter//dict_coef[algo[0]], tol=tol,
                    algo=algo[0], use_acc=algo[1])
            dict_Es[algo] = E

        current_palette = sns.color_palette("colorblind")
        dict_color = {}
        dict_color["cd"] = current_palette[1]
        dict_color['cdsym'] = current_palette[2]

        p_star = E_optimal[-1]
        for E in dict_Es.values():
            p_star = min(p_star, min(E))

        plt.close('all')
        fig, ax = plt.subplots(figsize=(10, 5))
        for i, algo in enumerate(all_algos):
            E = dict_Es[algo]
            use_acc = algo[1]
            linestyle = 'dashed' if use_acc else 'solid'

            ax.semilogy(
                dict_coef[algo[0]] * f_gap * np.arange(len(E)), E - p_star,
                label=algo_names[algo],
                color=dict_color[algo[0]], linestyle=linestyle)

        ax.semilogy(
            np.arange(len(E_optimal)), E_optimal - p_star,
            label=label_opt, color='black', linestyle='dashdot')

        dict_dataset = {}
        dict_dataset["rcv1_train"] = "rcv1"
        dict_dataset["real-sim"] = "real_sim"  # use _ not - for latex
        dict_dataset["leukemia"] = "leukemia"

        str_info = "%s (%i st columns)" % (dataset, n_features)
        title = pb + str_info

        plt.ylabel(r"$f(x^{(k)}) - f(x^{*})$")
        plt.xlabel("nb gradient calls")
        plt.ylim((1e-10, None))
        plt.tight_layout()

        plt.legend()
        plt.title(title.replace('_', ' '))
        plt.show(block=False)



.. image:: /auto_examples/images/sphx_glr_plot_cd_sym_001.png
    :alt: logregreal-sim (1000 st columns)
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Running CD
    Running CD - Anderson
    Running CD sym
    Running CD sym - Anderson
    Running CD
    Running CD - Anderson
    Running CD sym
    Running CD sym - Anderson





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  27.419 seconds)


.. _sphx_glr_download_auto_examples_plot_cd_sym.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_cd_sym.py <plot_cd_sym.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_cd_sym.ipynb <plot_cd_sym.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
